list_url = paste('http://www.who.int/csr/don/archive/year/', year, '/en/', sep="")
# getting the html
doc <- htmlParse(list_url)
cat('.')
# XPath to the PDF link only
output <- data.frame(
date =  xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlValue),
url = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlGetAttr, "href"),
year = year)
cat('.')
# ISSUE
# apparently the name field is returning an extra name somewhere
# name = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/span', xmlValue),
cat('.')
cat(' done')
return(output)
}
updateList <- scrapeList()
View(updateList)
View(updateList)
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(year = 2014) {
cat('Assembling a list of documents.')
# list of urls
list_url = paste('http://www.who.int/csr/don/archive/year/', year, '/en/', sep="")
# getting the html
doc <- htmlParse(list_url)
cat('.')
# XPath to the PDF link only
output <- data.frame(
date =  xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlValue),
url = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlGetAttr, "href"),
year = year)
cat('.')
# ISSUE
# apparently the name field is returning an extra name somewhere
# name = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/span', xmlValue),
cat('.')
cat('done.')
# fixing URLs
output$url <- sub('/entity/', 'http://www.who.int/', output$url)
return(output)
}
updateList <- scrapeList()
VieW(updateList)
View(updateList)
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(year = 2014) {
cat('Assembling a list of documents.')
# list of urls
list_url = paste('http://www.who.int/csr/don/archive/year/', year, '/en/', sep="")
# getting the html
doc <- htmlParse(list_url)
cat('.')
# XPath to the PDF link only
output <- data.frame(
date =  xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlValue),
url = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlGetAttr, "href"),
year = year)
cat('.')
# ISSUE
# apparently the name field is returning an extra name somewhere
# name = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/span', xmlValue),
cat('.')
cat('done.')
# fixing URLs
output$url <- sub('/entity/', 'http://www.who.int/', output$url)
output$url <- sub('index.html', '', output$url)
return(output)
}
updateList <- scrapeList()
View(updateList)
View(updateList)
library(RCurl)
library(XML)
letters
class(letters)
for (i in 1:letters) {
print(toupper(letter[i]))
}
let <- as.list(letters)
let
for (i in 1:letters) {
print(toupper(let[i]))
}
for (i in 1:length(letters)) {
print(toupper(let[i]))
}
for (i in 1:length(letters)) {
print(toupper(letters[i]))
}
for (i in 1:length(letters)) {
print(toupper(letters[i]))
}
for (i in 1:length(letters)) {
query_url <- paste0(base_url, toupper(letters[i]))
}
base_url = "http://www.imsdb.com/alphabetical/"
for (i in 1:length(letters)) {
query_url <- paste0(base_url, toupper(letters[i]))
}
for (i in 1:length(letters)) {
query_url <- paste0(base_url, toupper(letters[i]))
print(paste0(base_url, toupper(letters[i])))
}
## Scraper for RNI Colombia's Website.
# dependencies
library(XML)
library(RCurl)
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(url) {
cat('----------------------------------------\n')
cat('Scraping data from RNI-Colombia website.\n')
cat('----------------------------------------\n')
# getting the html
doc <- htmlParse(url)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tbody/tr/td[2]', xmlValue)
)
# results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
updateList <- scrapeList('http://rni.unidadvictimas.gov.co/?q=node/107')
View(updateList)
updateList
url = 'http://rni.unidadvictimas.gov.co/?q=node/107'
url
doc <- htmlParse(url)
dc
doc
url
doc <- htmlParse(url)
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[1]', xmlValue)
year
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr[2]/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody', xmlValue)
xpathSApply(doc, '//*[@id="main"]', xmlValue)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tbody/tr/td[2]', xmlValue)
)
View(output)
url = 'http://cifras.unidadvictimas.gov.co/Home/Vigencia_ocurrencia'
doc <- htmlParse(url)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tbody/tr/td[2]', xmlValue)
)
View(output)
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td[1]', xmlValue)
year
doc
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr[2]/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr[2]/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr[2]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table')
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr')
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td')
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr[1]/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[1]', xmlValue)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tr/td[2]', xmlValue)
)
View(output)
source('code/write_tables.R')
View(output)
output$number_of_victims <- gsub(".", "", output$number_of_victims)
output$number_of_events <- gsub(".", "", output$number_of_events)
View(output)
###################################################
###################################################
######### Scraping data from RNI's website ########
###################################################
###################################################
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(url) {
cat('----------------------------------------\n')
cat('Scraping data from RNI-Colombia website.\n')
cat('----------------------------------------\n')
# getting the html
doc <- htmlParse(url)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tr/td[2]', xmlValue)
)
# cleaning
output$number_of_victims <- gsub(".", "", output$number_of_victims)
output$number_of_events <- gsub(".", "", output$number_of_events)
# results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
# running the function
rniData <- scrapeList('http://cifras.unidadvictimas.gov.co/Home/Vigencia_ocurrencia')
View(rniData)
###################################################
###################################################
######### Scraping data from RNI's website ########
###################################################
###################################################
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(url) {
cat('----------------------------------------\n')
cat('Scraping data from RNI-Colombia website.\n')
cat('----------------------------------------\n')
# getting the html
doc <- htmlParse(url)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tr/td[2]', xmlValue)
)
# cleaning
output$number_of_victims <- gsub("[.]", "", output$number_of_victims)
output$number_of_events <- gsub("[.]", "", output$number_of_events)
# results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
# running the function
rniData <- scrapeList('http://cifras.unidadvictimas.gov.co/Home/Vigencia_ocurrencia')
View(rniData)
library(XML)
library(RCurl)
library(rjson)
title =  xpathSApply(doc, '//item')
url = 'http://healthmap.org/rss/ebola-all.rss'
doc <- xmlInternalTreeParse(url)
title =  xpathSApply(doc, '//item')
title
xpathSApply(doc, '//item/category/@domain["location"]', xmlValue)
xpathSApply(doc, '//item/category/@domain["location"]')
xpathSApply(doc, '//item/category/@domain')
xpathSApply(doc, '//item/category/@domain[.["location"]')
xpathSApply(doc, '//item/category/@domain[.="location"]')
xpathSApply(doc, '//item/category/@domain[.="location"]', xmlValue)
xpathSApply(doc, '//item/category/@domain[.="location"]')
xpathSApply(doc, '//item/category')
xpathSApply(doc, '//item/category/domain')
xpathSApply(doc, '//item/category')
xpathSApply(doc, '//item/category/@domain')
xpathSApply(doc, '//item/category/@domain["location"]')
xpathSApply(doc, '//item/category/@domain[.="location"]')
xpathSApply(doc, '//item/category/@domain[.="location"]', xmlAttrs)
xpathSApply(doc, '//item/category/@domain', xmlAttrs)
xpathSApply(doc, '//item/category', xmlAttrs)
xpathSApply(doc, '//item/category/@domain')
xpathSApply(doc, '//item/category/', xmlValue)
xpathSApply(doc, '//item/category', xmlValue)
xpathSApply(doc, '//item/category', xmlValue)[2]
xpathSApply(doc, '//item/category', xmlValue)
xpathSApply(doc, '//item/category')
xpathSApply(doc, '//item/category', xmlValue)
xpathSApply(doc, '//item/category[not(@location)]', xmlValue)
xpathSApply(doc, '//item/category[not(@desease)]', xmlValue)
xpathSApply(doc, '//item/category[not(@desease)]')
xpathSApply(doc, '//item/category/domain[not(@disease)]')
xpathSApply(doc, '//item/category/domain')
xpathSApply(doc, '//item/category/@domain')
xpathSApply(doc, '//item/category/@domain',xmlValue)
xpathSApply(doc, '//item/category/@domain', xmlValue)
xpathSApply(doc, '//item/category/domain', xmlValue)
xpathSApply(doc, '//item/category')
xpathSApply(doc, '//item/category[@domain]')
xpathSApply(doc, '//item/category[@domain]/@location')
xpathSApply(doc, '//item/category[@domain]/location')
xpathSApply(doc, '//item/category[@domain="location"]')
xpathSApply(doc, '//item/category[@domain="location"]', xmlValue)
# Function that fetches the data available
# in HealthMap's website and transforms
# the results into a data table.
scrapeHealthMap <- function() {
cat('----------------------------------------\n')
cat("Collecting the table from HealthMap.\n")
cat('----------------------------------------\n')
# HealthMap RSS feed
url = 'http://healthmap.org/rss/ebola-all.rss'
# getting the html
doc <- xmlInternalTreeParse(url)
# collecting the data into a data.frame
output <- data.frame(
title =  xpathSApply(doc, '//item/title', xmlValue),
publication_date = xpathSApply(doc, '//item/', xmlValue),
source_url = xpathSApply(doc, '//item/source/@url', xmlValue),
author = xpathSApply(doc, '//item/author', xmlValue),
country = xpathSApply(doc, '//item/category[@domain="location"]', xmlValue),
latitude = xpathSApply(doc, '//item/geo:lat', xmlValue),
longitude = xpathSApply(doc, '//item/geo:lon', xmlValue),
description = xpathSApply(doc, '//item/description', xmlValue)
)
# returning results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
healthMapData <- scrapeCDCData()
healthMapData <- scrapeHealthMap()
url = 'http://healthmap.org/rss/ebola-all.rss'
doc <- xmlInternalTreeParse(url)
title = xpathSApply(doc, '//item/title', xmlValue)
title
publication_date = xpathSApply(doc, '//item/', xmlValue)
xpathSApply(doc, '//item/')
xpathSApply(doc, '//item')
# Function that fetches the data available
# in HealthMap's website and transforms
# the results into a data table.
scrapeHealthMap <- function() {
cat('----------------------------------------\n')
cat("Collecting the table from HealthMap.\n")
cat('----------------------------------------\n')
# HealthMap RSS feed
url = 'http://healthmap.org/rss/ebola-all.rss'
# getting the html
doc <- xmlInternalTreeParse(url)
# collecting the data into a data.frame
output <- data.frame(
title = xpathSApply(doc, '//item/title', xmlValue),
publication_date = xpathSApply(doc, '//item/pubDate', xmlValue),
source_url = xpathSApply(doc, '//item/source/@url', xmlValue),
author = xpathSApply(doc, '//item/author', xmlValue),
country = xpathSApply(doc, '//item/category[@domain="location"]', xmlValue),
latitude = xpathSApply(doc, '//item/geo:lat', xmlValue),
longitude = xpathSApply(doc, '//item/geo:lon', xmlValue),
description = xpathSApply(doc, '//item/description', xmlValue)
)
# returning results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
healthMapData <- scrapeHealthMap()
xpathSApply(doc, '//item/source/@url', xmlValue)
xpathSApply(doc, '//item/source/@url')
xpathSApply(doc, '//item/source')
xpathSApply(doc, '//item/source[@url]')
xpathSApply(doc, '//item/source[@url]/@url')
xpathSApply(doc, '//item/source[@url]/@url', xmlAttribute)
xpathSApply(doc, '//item/source[@url]/@url', xmlAttributes)
xpathSApply(doc, '//item/source[@url]/@url', xmlValue)
?xmlAttributes
??xmlAttributes
xpathSApply(doc, '//item/source[@url]/@url', xmlAttrs)
xpathSApply(doc, '//item/source[@url]', xmlAttrs)
xpathSApply(doc, '//item/source', xmlAttrs)
xpathSApply(doc, '//item/source')
xpathSApply(doc, '//item/source[@url]')
xpathSApply(doc, '//item/source/[@url]')
xpathSApply(doc, '//item/source/@url')
xpathSApply(doc, '//item/source/@url', xmlValue)
xpathSApply(doc, '//item/source/@url', XMLAttributeValue)
xpathSApply(doc, '//item/source/@url')
class(xpathSApply(doc, '//item/source/@url)')
)
class(xpathSApply(doc, '//item/source/@url')
)
xpathSApply(doc, '//item/source/@url')
xpathSApply(doc, '//item/source/@url')[1]
xpathSApply(doc, '//item/source/@url')$url
xpathSApply(doc, '//item/source/@url')
xpathSApply(doc, '//item/source/@url', xmlGetAttr)
xpathSApply(doc, '//item/source', xmlGetAttr)
xpathSApply(doc, '//item/source', xmlGetAttr, 'url')
# Function that fetches the data available
# in HealthMap's website and transforms
# the results into a data table.
scrapeHealthMap <- function() {
cat('----------------------------------------\n')
cat("Collecting the table from HealthMap.\n")
cat('----------------------------------------\n')
# HealthMap RSS feed
url = 'http://healthmap.org/rss/ebola-all.rss'
# getting the html
doc <- xmlInternalTreeParse(url)
# collecting the data into a data.frame
output <- data.frame(
title = xpathSApply(doc, '//item/title', xmlValue),
publication_date = xpathSApply(doc, '//item/pubDate', xmlValue),
source_url = xpathSApply(doc, '//item/source', xmlGetAttr, 'url'),
author = xpathSApply(doc, '//item/author', xmlValue),
country = xpathSApply(doc, '//item/category[@domain="location"]', xmlValue),
latitude = xpathSApply(doc, '//item/geo:lat', xmlValue),
longitude = xpathSApply(doc, '//item/geo:lon', xmlValue),
description = xpathSApply(doc, '//item/description', xmlValue)
)
# returning results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
# running
healthMapData <- scrapeHealthMap()
xpathSApply(doc, '//item/author', xmlValue)
xpathSApply(doc, '//item/category[@domain="location"]', xmlValue)
xpathSApply(doc, '//item/geo:lat', xmlValue)
xpathSApply(doc, '//item/geo:lon', xmlValue)
xpathSApply(doc, '//item/geo:long', xmlValue)
xpathSApply(doc, '//item/description', xmlValue)
# Function that fetches the data available
# in HealthMap's website and transforms
# the results into a data table.
scrapeHealthMap <- function() {
cat('----------------------------------------\n')
cat("Collecting the table from HealthMap.\n")
cat('----------------------------------------\n')
# HealthMap RSS feed
url = 'http://healthmap.org/rss/ebola-all.rss'
# getting the html
doc <- xmlInternalTreeParse(url)
# collecting the data into a data.frame
output <- data.frame(
title = xpathSApply(doc, '//item/title', xmlValue),
publication_date = xpathSApply(doc, '//item/pubDate', xmlValue),
source_url = xpathSApply(doc, '//item/source', xmlGetAttr, 'url'),
author = xpathSApply(doc, '//item/author', xmlValue),
country = xpathSApply(doc, '//item/category[@domain="location"]', xmlValue),
latitude = xpathSApply(doc, '//item/geo:lat', xmlValue),
longitude = xpathSApply(doc, '//item/geo:long', xmlValue),
description = xpathSApply(doc, '//item/description', xmlValue)
)
# returning results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
# running
healthMapData <- scrapeHealthMap()
View(healthMapData)
whoData <- read.csv(url('http://data.hdx.rwlabs.org/storage/f/2014-10-25T15%3A01%3A26.408Z/ebola-data-db-format.csv'))
library(RCurl)
whoData <- read.csv(getURL('http://data.hdx.rwlabs.org/storage/f/2014-10-25T15%3A01%3A26.408Z/ebola-data-db-format.csv'))
whoData <- read.csv(url(getURL('http://data.hdx.rwlabs.org/storage/f/2014-10-25T15%3A01%3A26.408Z/ebola-data-db-format.csv')))
getURL('http://data.hdx.rwlabs.org/storage/f/2014-10-25T15%3A01%3A26.408Z/ebola-data-db-format.csv')
setwd("~/Documents/Programming/HDXScrapers/hdxscraper-who-gar-indicators")
download.file('http://data.hdx.rwlabs.org/storage/f/2014-10-25T15%3A01%3A26.408Z/ebola-data-db-format.csv', destfile = 'data/data.csv')
download.file('http://data.hdx.rwlabs.org/storage/f/2014-10-25T15%3A01%3A26.408Z/ebola-data-db-format.csv', destfile = 'data/data.csv', method = 'wget')
?download.file
download.file('http://data.hdx.rwlabs.org/storage/f/2014-10-25T15%3A01%3A26.408Z/ebola-data-db-format.csv', destfile = 'data/data.csv', method = 'curl')
whoData <- read.csv('data/data.csv')
download.file('http://data.hdx.rwlabs.org/storage/f/2014-10-25T15%3A01%3A26.408Z/ebola-data-db-format.csv', destfile = 'data/data.csv', method = 'wget')
# Getting the download link from CKAN
getResourceURL <- function(id = NULL) {
# Building URL
cUrl = 'https://data.hdx.rwlabs.org/api/action/resource_show?id='
qUrl = paste(cUrl, id, sep="")
# Getting JSON document
doc <- fromJSON(getURL(qUrl))
return(doc$result$url)
}
getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1')
library(rjson)
# Getting the download link from CKAN
getResourceURL <- function(id = NULL) {
# Building URL
cUrl = 'https://data.hdx.rwlabs.org/api/action/resource_show?id='
qUrl = paste(cUrl, id, sep="")
# Getting JSON document
doc <- fromJSON(getURL(qUrl))
return(doc$result$url)
}
getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1')
# Downloading the file
download.file(getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1'), destfile = 'data/data.csv', method = 'wget')
csvText = (getURL(getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1'))
csvText = (getURL(getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1')))
whoData <- read.csv(text = csvText)
getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1')
download.file(getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1'), 'data/data.csv')
download.file(getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1'), 'data/data.csv', method = 'curl')
download.file(getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1'), 'data/data.csv', method = 'internal')
download.file(getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1'), 'data/data.csv', method = 'lynx')
download.file(getResourceURL('f48a3cf9-110e-4892-bedf-d4c1d725a7d1'), 'data/data.csv', method = 'wget')
